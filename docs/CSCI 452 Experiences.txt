Names: Stuart Nevans Locke, Jacob Doll, Eric Chen
Team 3
Experiences


Team Experience:
We made the initial decision on what we wanted to work on for the project around February or March where we decided upon a shell-like program that could take files (specifically binary files), even ones compiled on other systems, and let us run them on the OS. The three projects we committed to making were a file system, paging and virtual memory, and an ELF loader. Eric Chen worked on the file system, Stuart Nevans Locke worked on paging and virtual memory, and Jacob Doll worked on the ELF loader. Initially we worked separately and independently on our parts of the project, while still communicating how far we were and what issues we encountered. Once we began finishing our individual modules for the project, we merged them together and began troubleshooting the issues that arrived. We ran into further issues when testing the software on hardware, with the hardware having different memory parameters compared to running on QEMU. After some debugging, we managed to have the OS run on hardware and QEMU though only paging and the ELF loader were successfully integrated into the software, with the file system ultimately being unusable in comparison.




Working on File System (Eric Chen):
The decision to use the FAT32 file system design came rather early in the semester (around February or March) and I committed to working on it for this project. To begin, I first attempted to compile and run the baseline OS code. Unfortunately, the code failed to compile on my personal computer, so I had to spend some time attempting to debug this issue and make the code compilable. Ultimately, I found the issue to lie with the bootstrap code and managed to make some changes to fix some issues. However, at this point I had already taken about a week in my attempt to fix the issue and realized I was better off just programming on the DSL machines and transferring any work I did to and from my personal computer to the DSL machine.
I began researching the FAT32 file system design next, first by consulting the wikipedia page on it to gather background information about the file system. I had little to no prior knowledge on the FAT file system in any form, so I spent a significant amount of time familiarizing myself with the design and various nuances of the system. I made the initial decision to begin coding based on what information I gathered from my research, before consulting more technical guides such as the FAT page of OSDev and Microsoft’s documentation of the FAT32 file system in fatgen103.pdf. This proved to be a mistake as my initial design of the file system failed to be coherent or workable beyond a few structures that were later updated to fit FAT32 standards. After making changes to my initial design that factored in the wealth of knowledge from more technical sources I began developing a more proper FAT32 file system.
While I started out by making a few functions for file creation and deletion, my first real step in constructing a FAT32 file system was in designing the BIOS Parameter Block (BPB). The actual structure itself was fairly simple since all of the fields of the BPB are well documented so it was a mere matter of translating that information into code. I also set up the extended boot record for FAT32 in the same manner. From there finding the rest of the information about the file system such as the File Allocation Table and data area became a matter of knowing what values to use from the BPB to calculate where sectors began and how large areas were. The next major problem to arise was finding the BPB itself, since it was located on disk in a certain area (sector0) and I had no way at the time of finding and reading that area. Luckily one of my teammates suggested that I use ATA PIO drivers to find this disk sector and I ultimately used his previously made code on ATA drivers with his permission for my file system. Some simple testing showed that it compiled and so I used it to read from the disk sector the BPB and copied the data from the BPB into my BPB structure. Unfortunately due to time constraints, I decided to work on getting file reading and writing done first before I spent too much time testing the ATA driver and BPB sector reading.
My decision to focus on directory reading and writing came as a result of the research I did and how I found that compared to the FAT32 file system structure, there was less concise information about reading and writing. I spent even more time trying to figure out how the FAT works in relation to directory reading and cluster chaining. Many sources online had different interpretations on directory reading and writing but few had enough detail for me to choose a singular source, so I had to pull from multiple sources in designing the directory reading and writing. My design closely followed the FAT OSDev interpretation of directory reading, while the directory writing part followed another source online that had a simplified structure for writing directories to the root directory, FAT, and the data area. Ultimately, a majority of my time was spent writing these functions as well as other helper functions and main functions such as searching through directories and creating files. Time spent developing here also led to me choosing to make the root directory a separate structure saved in the file system instead of being pulled straight from the disk sector, as it was simpler to have the root directory accessible easier than having to pull it from disk every time.
Ultimately, all of this code was compilable and fit the design structures I had researched from FAT32. However, the time I spent developing the code, reformatting what I wrote depending on new information I read, and generally researching how a FAT32 file system worked and understanding it took enough time that I was unable to successfully have the file system actually run properly in tangent with the other modules. The file system itself does not interfere with the OS and the other modules, but it fails in set up. In the end, my decision to develop the code before I fully understood the FAT32 file system led to me spending too much time developing and restructuring my code and I failed to incorporate the file system with the rest of the project. I intend to learn from these mistakes and next time spend more time fully understanding what I intend to design and program before I develop software. Next time, I will budget my time better so that I am not forced to choose between development and testing and be able to develop a better product.




Working on Paging and Virtual Memory (Stuart Nevans Locke):
I dedicated the first week or two to exclusively reading about how paging works on x86. I already had some familiarity with the ideas, so understanding exactly what the MMU expects wasn’t too difficult. One of the interesting things I saw is that a lot of the more recently written blog posts and information about paging were written for 64 bit x86. A lot of the 32 bit examples I could find contained broken links. This makes sense given that 64 bit is unquestionably the standard nowadays. Once I had a reasonable understanding of the required data structures, I started coding. My goal was to create a usable API with at least a few weeks remaining in the class to allow Jacob to properly test his elf loader.
The first thing I did was create basic code that turned on paging and identity mapped the first few megabytes. I planned on having paging be a separate module that was initialized before the kmem manager. That would allow kmem to work with just virtual addresses. This brought up the question of how I would then get memory to use for my page tables and directories. I decided to try to just compile it into the ELF. This initially seemed to work, but as I increased the static number of pages, I got odd smiley faces drawn to the console. It seems this happened because the page tables overlapped with other necessary memory (probably for some graphics).
        This brought me back to the question of how I would then be able to find memory to use for my page tables. I decided to hook into kmem and take part of the first region it finds to use for paging. Through this process, I found debugging messed up page tables could be very difficult. When a triple fault occurs, the CPU just resets with no indication of what specifically caused that. This means if your page table is messed up sufficiently, it can be very difficult to determine what caused that. 
With everything seemingly working in QEMU, I decided to test on hardware just a few days before the project was due. Using a bootable USB we ran it and found the system instantly resetting before anything could visibly be printed to the screen. After a bunch of debugging (including adding delays and taking video of the screen because things would be cleared before I could get a chance to read them). We found out that the issue came essentially because the hardware had so much more memory. My implementation did an identity mapping for every single block that the kmem allocator was made aware of. On hardware with 16GB of memory running in 32 bit, that pretty much means the whole address space will be identity mapped. That’s memory that could overlap with a variety of things including our stacks and more. After finding this out, I restructured the system so that only things that needed to be identity mapped (the page table and page directories). This seemed to get the system to run on hardware. 
        One note on the bright side: having paging enabled and writing a page fault handler made things easier to debug multiple times. For example, when changes were made to the ELF loader that resulted in there being a bug when program headers were not aligned and spanned multiple pages, there was a clear error that told us there was a page fault where the program was being loaded. This made it very quick to debug.
        There are still several more things I would like to implement. It would be nice to have a page fault handler that gave even more information such as the process id and instruction pointer (and maybe even a dump of the instruction that caused the page fault as the process id). Theoretically this would also eventually be extended to allow for swapping and copy on write pages. I would also like to actually remap the kernel at a higher address rather than in the bottom of memory. This would mean errors such as NULL pointer dereferences would cause a page fault rather than just writing to memory. Remapping the kernel would have required us to compile the kernel as position independent or expecting to be at a certain higher address, and we did not manage to do this. Just adding the position independent flags didn’t result in a bootable image. It would also be nice to have some sort of struct page like the linux kernel does to help with bookkeeping about all our pages.  
        Overall, I learned a lot about how paging actually works on OSes. I learned about the structure of the multilevel page table, and the various flags for the page table and directory entries. I also learned how much more complicated paging is in practice than it sounded like when just reading online tutorials. It’s unusual to come across one that mentions the debugging process to deal with paging issues and it’s very unlikely for all my code to just work on the first try. One of the things I learned about most was how you can’t just take your entire physical address space for granted as good memory. If you aren’t careful, it’s easy to end up overwriting memory used for other things. I also learned how difficult it can be to integrate paging in to other components written with no concept of virtual memory and relying on physical memory such as the physical allocator. Overall, I would say that the virtual memory system was pretty successful as I gave Jacob a fair bit of time to test his ELF Loader and the virtual memory is in a runnable state.


Working on ELF Loader (Jacob Doll):
        Much of the first week of development had nothing to do with writing code at all. I realized early on that in order to test my ELF loader I would actually need something to test. Therefore, much of my time was spent refactoring the build pipeline. Our baseline code compiled all user applications into the kernel. My goal was to separate all user code from the kernel. While seemingly simple this task took more time then I was expecting as I had to write multiple make files.
        Now that I had a build system that could support separation of kernel and user programs, I could start researching the ELF binary format. My use case was purely being able to execute a program so what I had to implement from a loading perspective was quite simple. Most of the structures were pulled straight from the Linux source. Also given that paging was implemented within a working state I could also map binary files without having to deal with relocations. As the loader itself was fully developed I began to realize most of my struggles would not be in development but getting userspace programs to compile in the first place.
        The way GCC determines if a program is executable is by looking for the _start symbol. However, none of our user programs had this symbol so I had to provide this symbol myself. This was easy enough, I created an entry.S file that was compiled into each program, containing an _start function. At first I was thinking that how main would get called would be complicated given the way the baseline system passed in the stack. However, again this was relatively easy, I simply just jumped to main so that the stack remained intact. Along with entry.S being compiled into each user program, so did ulibc and ulibs. Another consideration that had to be accommodated was the fact there was no guarantee that paging would work so I compiled each program with position independent code so if needed I could do manual relocations.
 Now I had an ELF loader and compiled user programs to test against, but how would I load these programs into memory. Luckily after looking at the source for BuildImage I realized I could use this to add the programs to the image and tell the bootloader where to put them in physical memory. However, unbeknownst to me this would cause issues down the road. Now all I had to do was pass in the physical memory address of the binary and finally I could load ELF binaries and execute them. I then edited how execp works so that instead of passing in a function pointer it takes a memory address.
Now that I had one program working, the idle program, I attempted to get more than one program to work. This was the beginning of my issues. I slowly realized that I had limited access to how much memory I could use under 0x100000. I had to edit where the physical memory cutoff was in the physical memory allocator so that I could reserve memory for the binaries. But this was severely limiting, I could only realistically put about six programs in memory before I ran into issues.Without having access to higher memory at boot time, this was a limitation that I had to deal with and could not fix.
I now had a working ELF loader that could load more than one program and execute them. Yet, this was only on my system. Disaster struck when we tried running the system on another computer. While the OS would compile on the lab computers, it would triple fault when running. We could not figure out what the issue was but we knew it had to do something with something being overwritten in memory. After an hour or two we realized that the bootloader was overwriting part of the kernel. Now on my system the kernel was smaller as I was compiling using a newer version of GCC. Yet on the lab computers the binary was larger and since I was loading the first program at 0x20000 it was overwriting the kernel. After discovering this we edited where binaries were put in memory and we got the OS working the lab machines. Goes to show what a few major versions of GCC can do for program size. 
Honestly this project has taught me more about how programs are compiled then how to load programs into memory. All of my issues revolved around how to compile the user programs and the differences in binaries depending on the system compiling on.